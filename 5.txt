import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier

# Step 1: Generate 100 random values in the range [0,1]
np.random.seed(42)  # For reproducibility
x = np.random.rand(100, 1)  # Generate 100 random points

# Step 2: Label the first 50 points
y = np.array(['Class1' if xi <= 0.5 else 'Class2' for xi in x[:50]])  # Label based on condition

# Step 3: Train KNN Classifier and classify the remaining 50 points
k_values = [1, 2, 3, 4, 5, 20, 30]
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(x[:50], y)  # Train only on the first 50 labeled points
    y_pred = knn.predict(x[50:])  # Predict labels for x51 to x100

    # Step 4: Display results
    print(f"\nResults for k = {k}:")
    for i, label in enumerate(y_pred, start=51):
        print(f"x{i} = {x[i-1][0]:.3f} â†’ Classified as {label}")

# Step 5: Visualization (only for the last k-value run)
plt.figure(figsize=(8, 5))
plt.scatter(x[:50], np.zeros(50), c=['blue' if yi == 'Class1' else 'red' for yi in y], label="Labeled Data")
plt.scatter(x[50:], np.zeros(50), c='black', marker='x', label="Unlabeled Data")
plt.xlabel("x values")
plt.ylabel("Classification")
plt.title("KNN Classification of Random Data Points")
plt.legend()
plt.show()
